---
# Source: nri-bundle/charts/nri-prometheus/templates/serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: nri-prometheus
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
  annotations:
    null
    
---
# Source: nri-bundle/charts/newrelic-pixie/templates/secret.yaml

apiVersion: v1
kind: Secret
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-pixie
    app.kubernetes.io/name: newrelic-pixie
    chart: newrelic-pixie-0.1.0-alpha.9
    release: nri-bundle
  name: nri-bundle-newrelic-pixie-secrets
type: Opaque
data:
  newrelicLicenseKey: OWYxZjgzN2VlOTJlNjNjNjFhOGMwMzRiY2MzMDBlZTVjNjY0TlJBTA==
  pixieApiKey: YTZjN2U3NTktMDhmNC00NGRjLWFlYWYtM2E4NjMzOTE1ZjFk
---
# Source: nri-bundle/charts/kube-state-metrics/templates/role.yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: kube-state-metrics-2.13.2
    app.kubernetes.io/instance: nri-bundle
  name: nri-bundle-kube-state-metrics
rules:

- apiGroups: ["certificates.k8s.io"]
  resources:
  - certificatesigningrequests
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - cronjobs
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - daemonsets
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - deployments
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - endpoints
  verbs: ["list", "watch"]

- apiGroups: ["autoscaling"]
  resources:
  - horizontalpodautoscalers
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - jobs
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - limitranges
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - mutatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - namespaces
  verbs: ["list", "watch"]

- apiGroups: ["networking.k8s.io"]
  resources:
  - networkpolicies
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - nodes
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumeclaims
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumes
  verbs: ["list", "watch"]

- apiGroups: ["policy"]
  resources:
    - poddisruptionbudgets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - pods
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - replicasets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - replicationcontrollers
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - resourcequotas
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - secrets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - services
  verbs: ["list", "watch"]

- apiGroups: ["apps"]
  resources:
  - statefulsets
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - storageclasses
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - validatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - volumeattachments
  verbs: ["list", "watch"]

---
# Source: nri-bundle/charts/kube-state-metrics/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-kube-state-metrics
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: "kube-state-metrics-2.13.2"
    app.kubernetes.io/instance: "nri-bundle"
    app.kubernetes.io/version: "1.9.8"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/instance: "nri-bundle"
    spec:
      hostNetwork: false
      serviceAccountName: nri-bundle-kube-state-metrics
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsUser: 65534
      containers:
      - name: kube-state-metrics
        args:


        - --collectors=certificatesigningrequests


        - --collectors=configmaps


        - --collectors=cronjobs


        - --collectors=daemonsets


        - --collectors=deployments


        - --collectors=endpoints


        - --collectors=horizontalpodautoscalers


        - --collectors=ingresses


        - --collectors=jobs


        - --collectors=limitranges


        - --collectors=mutatingwebhookconfigurations


        - --collectors=namespaces


        - --collectors=networkpolicies


        - --collectors=nodes


        - --collectors=persistentvolumeclaims


        - --collectors=persistentvolumes


        - --collectors=poddisruptionbudgets


        - --collectors=pods


        - --collectors=replicasets


        - --collectors=replicationcontrollers


        - --collectors=resourcequotas


        - --collectors=secrets


        - --collectors=services


        - --collectors=statefulsets


        - --collectors=storageclasses


        - --collectors=validatingwebhookconfigurations



        - --collectors=volumeattachments





        - --telemetry-port=8081
        imagePullPolicy: IfNotPresent
        image: "k8s.gcr.io/kube-state-metrics/kube-state-metrics:v1.9.8"
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/job-patchWebhook.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: nri-bundle-nri-metadata-injection-admission-patch
  namespace: newreliclog
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission-patch
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
spec:
  template:
    metadata:
      name: nri-bundle-nri-metadata-injection-admission-patch
      labels:
        app: nri-metadata-injection-admission-patch
        app.kubernetes.io/name: nri-metadata-injection
        helm.sh/chart: nri-metadata-injection-1.5.1
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/version: "1.5.0"
    spec:
      containers:
        - name: patch
          image: jettech/kube-webhook-certgen:v1.5.0
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=nri-bundle-nri-metadata-injection
            - --namespace=newreliclog
            - --secret-name=nri-bundle-nri-metadata-injection-admission
            - --patch-failure-policy=Ignore
            - --patch-validating=false
      restartPolicy: OnFailure
      serviceAccountName: nri-bundle-nri-metadata-injection-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000

---
# Source: nri-bundle/charts/pixie-chart/templates/02_etcd.yaml

---
# Source: nri-bundle/charts/newrelic-logging/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:     
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: nri-bundle
    app.kubernetes.io/name: newrelic-logging
  name: nri-bundle-newrelic-logging
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-newrelic-logging
subjects:
- kind: ServiceAccount
  name: nri-bundle-newrelic-logging
  namespace: newreliclog
---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-2.4.8
    release: nri-bundle
    mode: privileged
  name: nri-bundle-newrelic-infrastructure
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: newrelic-infrastructure
      release: nri-bundle
  template:
    metadata:
      labels:
        app: newrelic-infrastructure
        release: nri-bundle
        mode: privileged
    spec:
      serviceAccountName: nri-bundle-newrelic-infrastructure
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
        - name: newrelic-infrastructure
          image: "newrelic/infrastructure-k8s:2.6.1"
          imagePullPolicy: "IfNotPresent"
          securityContext:
            privileged: true
          env:
            - name: NRIA_LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: nri-bundle-newrelic-infrastructure-config
                  key: license
            - name: "CLUSTER_NAME"
              value: api-kpmgocp-stotenrhos-com:6443
            - name: "NRK8S_NODE_NAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRIA_DISPLAY_NAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRIA_CUSTOM_ATTRIBUTES"
              value: '{"clusterName":"$(CLUSTER_NAME)"}'
            - name: "NRIA_PASSTHROUGH_ENVIRONMENT"
              value: "KUBERNETES_SERVICE_HOST,KUBERNETES_SERVICE_PORT,CLUSTER_NAME,CADVISOR_PORT,NRK8S_NODE_NAME,KUBE_STATE_METRICS_URL,KUBE_STATE_METRICS_POD_LABEL,TIMEOUT,ETCD_TLS_SECRET_NAME,ETCD_TLS_SECRET_NAMESPACE,API_SERVER_SECURE_PORT,KUBE_STATE_METRICS_SCHEME,KUBE_STATE_METRICS_PORT,SCHEDULER_ENDPOINT_URL,ETCD_ENDPOINT_URL,CONTROLLER_MANAGER_ENDPOINT_URL,API_SERVER_ENDPOINT_URL,DISABLE_KUBE_STATE_METRICS,DISCOVERY_CACHE_TTL"
          volumeMounts:
            - name: dev
              mountPath: /dev
            - name: host-docker-socket
              mountPath: /var/run/docker.sock
            - name: log
              mountPath: /var/log
            - name: host-volume
              mountPath: /host
              readOnly: true
          resources:
            limits:
              memory: 300M
            requests:
              cpu: 100m
              memory: 150M
            
      volumes:
        - name: dev
          hostPath:
            path: /dev
        - name: host-docker-socket
          hostPath:
            path: /var/run/docker.sock
        - name: log
          hostPath:
            path: /var/log
        - name: host-volume
          hostPath:
            path: /
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  namespace: newreliclog
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"

---
# Source: nri-bundle/charts/nri-prometheus/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nri-bundle-nri-prometheus
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-prometheus
subjects:
- kind: ServiceAccount
  name: nri-prometheus
  namespace: newreliclog
---
# Source: nri-bundle/charts/nri-kube-events/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"
  name: nri-bundle-nri-kube-events
rules:
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["get", "watch", "list"]
---
# Source: nri-bundle/charts/newrelic-logging/templates/podsecuritypolicy.yaml


---
# Source: nri-bundle/charts/kube-state-metrics/templates/podsecuritypolicy.yaml


---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/podsecuritypolicy.yaml


---
# Source: nri-bundle/charts/kube-state-metrics/templates/stsdiscovery-rolebinding.yaml


---
# Source: nri-bundle/charts/kube-state-metrics/templates/pdb.yaml

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/rolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  namespace: newreliclog
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: nri-bundle-nri-metadata-injection-admission
subjects:
  - kind: ServiceAccount
    name: nri-bundle-nri-metadata-injection-admission
    namespace: newreliclog

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-metadata-injection-admission
subjects:
  - kind: ServiceAccount
    name: nri-bundle-nri-metadata-injection-admission
    namespace: newreliclog

---
# Source: nri-bundle/charts/newrelic-pixie/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-newrelic-pixie
  namespace: newreliclog
  labels:
    
    app: newrelic-pixie
    app.kubernetes.io/name: newrelic-pixie
    chart: newrelic-pixie-0.1.0-alpha.9
    release: nri-bundle
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: newrelic-pixie
      release: nri-bundle
  template:
    metadata:
      labels:
        app.kubernetes.io/name: newrelic-pixie
        release: nri-bundle
    spec:
      containers:
      - name: newrelic-pixie
        image: "newrelic/newrelic-pixie-integration:0.1.7"
        imagePullPolicy: "IfNotPresent"
        env:
        - name: CLUSTER_NAME
          value: api-kpmgocp-stotenrhos-com:6443
        - name: NR_LICENSE_KEY
          valueFrom:
            secretKeyRef:
              name: nri-bundle-newrelic-pixie-secrets
              key: newrelicLicenseKey
        - name: PIXIE_API_KEY
          valueFrom:
            secretKeyRef:
              name: nri-bundle-newrelic-pixie-secrets
              key: pixieApiKey
        - name: PIXIE_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        resources:
          limits:
            memory: 250M
          requests:
            cpu: 100m
            memory: 250M
          

---
# Source: nri-bundle/charts/nri-kube-events/templates/secret.yaml

apiVersion: v1
kind: Secret
metadata:
  name: nri-bundle-nri-kube-events-config
  namespace: newreliclog
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"
type: Opaque
data:
  licenseKey: OWYxZjgzN2VlOTJlNjNjNjFhOGMwMzRiY2MzMDBlZTVjNjY0TlJBTA==

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/daemonset-windows.yaml


---
# Source: nri-bundle/charts/kube-state-metrics/templates/kubeconfig-secret.yaml

---
# Source: nri-bundle/charts/pixie-chart/templates/04_vizier_persistent.yaml

---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: cloud-conn-service-account
  namespace: newreliclog
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
    vizier-updater-dep: "true"
  name: updater-service-account
  namespace: newreliclog
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  annotations:
    
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl
  namespace: newreliclog
spec:
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - '*'
  fsGroup:
    rule: RunAsAny
  hostIPC: true
  hostNetwork: true
  hostPID: true
  hostPorts:
  - max: 65535
    min: 0
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl-psp
  namespace: newreliclog
rules:
- apiGroups:
  - policy
  resourceNames:
  - pl
  resources:
  - podsecuritypolicies
  verbs:
  - use
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
    vizier-updater-dep: "true"
  name: pl-updater-role
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  - apps
  - rbac.authorization.k8s.io
  - extensions
  - etcd.database.coreos.com
  - batch
  - nats.io
  - policy
  resources:
  - clusterroles
  - clusterrolebindings
  - configmaps
  - secrets
  - pods
  - services
  - deployments
  - daemonsets
  - persistentvolumes
  - persistentvolumeclaims
  - roles
  - rolebindings
  - serviceaccounts
  - etcdclusters.etcd.database.coreos.com
  - etcdclusters
  - statefulsets
  - cronjobs
  - jobs
  - natsclusters
  - podsecuritypolicies
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl-cloud-connector-role
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  - services
  - endpoints
  - namespaces
  - jobs
  - events
  - pods/log
  verbs:
  - '*'
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-node-view
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - watch
  - list
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-vizier-certmgr
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - secrets
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-vizier-metadata
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - namespaces
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl-psp-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pl-psp
subjects:
- kind: ServiceAccount
  name: updater-service-account
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
    vizier-updater-dep: "true"
  name: pl-updater-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl-updater-role
subjects:
- kind: ServiceAccount
  name: updater-service-account
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl-cloud-connector-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl-cloud-connector-role
subjects:
- kind: ServiceAccount
  name: cloud-conn-service-account
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-node-view-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl-node-view
subjects:
- kind: ServiceAccount
  name: default
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-vizier-certmgr
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl-vizier-certmgr
subjects:
- kind: ServiceAccount
  name: default
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-vizier-metadata-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl-vizier-metadata
subjects:
- kind: ServiceAccount
  name: default
  namespace: newreliclog
---
apiVersion: v1
data:
  PL_CLIENT_TLS_CERT: /certs/client.crt
  PL_CLIENT_TLS_KEY: /certs/client.key
  PL_SERVER_TLS_CERT: /certs/server.crt
  PL_SERVER_TLS_KEY: /certs/server.key
  PL_TLS_CA_CERT: /certs/ca.crt
kind: ConfigMap
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: pl-cloud-connector-tls-config
  namespace: newreliclog
---
apiVersion: v1
data:
  PL_CLIENT_TLS_CERT: /certs/client.crt
  PL_CLIENT_TLS_KEY: /certs/client.key
  PL_SERVER_TLS_CERT: /certs/server.crt
  PL_SERVER_TLS_KEY: /certs/server.key
  PL_TLS_CA_CERT: /certs/ca.crt
kind: ConfigMap
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: pl-tls-config
  namespace: newreliclog
---
apiVersion: v1
data:
  envoy.yaml: |
    static_resources:
      listeners:
      - name: listener_0
        address:
          socket_address: { address: 0.0.0.0, port_value: 55000 }
        filter_chains:
        - filters:
          - name: envoy.http_connection_manager
            config:
              access_log:
              - name: envoy.file_access_log
                config:
                  path: "/dev/stdout"
              codec_type: auto
              stat_prefix: ingress_http
              route_config:
                name: local_route
                virtual_hosts:
                - name: local_service
                  domains: ["*"]
                  routes:
                  - match:
                      prefix: "/px.vizier.services.query_broker"
                    route:
                      cluster: query_broker_service
                  - match:
                      prefix: "/px.api.vizierpb.VizierService"
                    route:
                      cluster: query_broker_service
                      timeout: 3600s
                  - match:
                      prefix: "/px.api.vizierpb.VizierDebugService"
                    route:
                      cluster: cloud_connector_service
                      timeout: 3600s
                  - match:
                      prefix: "/healthz"
                    route:
                      cluster: query_broker_service
                  cors:
                    allow_origin_string_match:
                    - prefix: "*"
                    allow_methods: GET, PUT, DELETE, POST, OPTIONS
                    allow_headers: >-
                      keep-alive,user-agent,cache-control,content-type,content-transfer-encoding,
                      x-accept-content-transfer-encoding,x-accept-response-streaming,
                      x-user-agent,x-grpc-web,authorization,grpc-timeout
                    max_age: "1728000"
                    expose_headers: grpc-status,grpc-message,grpc-timeout
              http_filters:
              - name: envoy.grpc_web
              - name: envoy.cors
              - name: envoy.router
          tls_context:
            common_tls_context:
              alpn_protocols: "h2,http/1.1"
              tls_certificates:
                - certificate_chain:
                    filename: "/proxy-certs/tls.crt"
                  private_key:
                    filename: "/proxy-certs/tls.key"
      clusters:
      - name: query_broker_service
        connect_timeout: 0.25s
        type: logical_dns
        http2_protocol_options: {}
        lb_policy: round_robin
        hosts:
        - socket_address:
            address: vizier-query-broker.newreliclog.svc
            port_value: 50300
        tls_context:
          common_tls_context:
            tls_certificates:
              - certificate_chain:
                  filename: "/certs/client.crt"
                private_key:
                  filename: "/certs/client.key"

      - name: cloud_connector_service
        connect_timeout: 0.25s
        type: logical_dns
        http2_protocol_options: {}
        lb_policy: round_robin
        hosts:
        - socket_address:
            address: vizier-cloud-connector.newreliclog.svc
            port_value: 50800
        tls_context:
          common_tls_context:
            tls_certificates:
              - certificate_chain:
                  filename: "/certs/client.crt"
                private_key:
                  filename: "/certs/client.key"

      - name: api_service
        connect_timeout: 0.25s
        type: logical_dns
        http2_protocol_options: {}
        lb_policy: round_robin
        hosts:
        - socket_address:
            address: vizier-api-service.newreliclog.svc
            port_value: 50200
        tls_context:
          common_tls_context:
            tls_certificates:
              - certificate_chain:
                  filename: "/certs/client.crt"
                private_key:
                  filename: "/certs/client.key"
kind: ConfigMap
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: proxy-envoy-config
  namespace: newreliclog
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: kelvin-service
  namespace: newreliclog
spec:
  clusterIP: None
  ports:
  - name: tcp-http2
    port: 59300
    protocol: TCP
    targetPort: 59300
  selector:
    app: pl-monitoring
    component: vizier
    name: kelvin
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-certmgr
  namespace: newreliclog
spec:
  ports:
  - name: tcp-http2
    port: 50900
    protocol: TCP
    targetPort: 50900
  selector:
    app: pl-monitoring
    component: vizier
    name: vizier-certmgr
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: vizier-cloud-connector
  namespace: newreliclog
spec:
  ports:
  - name: tcp-http2
    port: 50800
    protocol: TCP
    targetPort: 50800
  selector:
    app: pl-monitoring
    component: vizier
    name: vizier-cloud-connector
    vizier-bootstrap: "true"
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-metadata
  namespace: newreliclog
spec:
  ports:
  - name: tcp-http2
    port: 50400
    protocol: TCP
    targetPort: 50400
  selector:
    app: pl-monitoring
    component: vizier
    name: vizier-metadata
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-proxy-service
  namespace: newreliclog
spec:
  ports:
  - name: tcp-https
    port: 443
    protocol: TCP
    targetPort: 55000
  selector:
    app: pl-monitoring
    component: vizier
    name: vizier-proxy
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-query-broker
  namespace: newreliclog
spec:
  ports:
  - name: tcp-http2
    port: 50300
    protocol: TCP
    targetPort: 50300
  - name: tcp-grpc-web
    port: 50305
    protocol: TCP
    targetPort: 50305
  selector:
    app: pl-monitoring
    component: vizier
    name: vizier-query-broker
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: kelvin
  namespace: newreliclog
spec:
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: kelvin
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: kelvin
        plane: data
    spec:
      containers:
      - env:
        - name: PL_HOST_PATH
          value: /host
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        - name: PL_SENTRY_DSN
          value: ""
        - name: PL_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: PL_HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        - name: PL_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: TCMALLOC_SAMPLE_PARAMETER
          value: "1048576"
        envFrom:
        - configMapRef:
            name: pl-tls-config
        image: gcr.io/pixie-oss/pixie-prod/vizier/kelvin_image:0.7.13
        name: app
        ports:
        - containerPort: 59300
        resources: {}
        volumeMounts:
        - mountPath: /certs
          name: certs
        - mountPath: /sys
          name: sys
          readOnly: true
      initContainers:
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/readyz"; until [ $(curl
          -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do echo "waiting
          for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-cloud-connector
        - name: SERVICE_PORT
          value: "50800"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: cc-wait
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/healthz"; until [
          $(curl -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do
          echo "waiting for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-query-broker
        - name: SERVICE_PORT
          value: "50300"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: qb-wait
      terminationGracePeriodSeconds: 30
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
      - hostPath:
          path: /sys
          type: Directory
        name: sys
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-certmgr
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-certmgr
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-certmgr
        plane: control
    spec:
      containers:
      - env:
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        - name: PL_SENTRY_DSN
          value: ""
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        - name: PL_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        envFrom:
        - configMapRef:
            name: pl-tls-config
        image: gcr.io/pixie-oss/pixie-prod/vizier/certmgr_server_image:0.7.13
        livenessProbe:
          httpGet:
            path: /healthz
            port: 50900
            scheme: HTTPS
        name: app
        ports:
        - containerPort: 50900
        volumeMounts:
        - mountPath: /certs
          name: certs
      initContainers:
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/readyz"; until [ $(curl
          -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do echo "waiting
          for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-cloud-connector
        - name: SERVICE_PORT
          value: "50800"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: cc-wait
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: vizier-cloud-connector
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-cloud-connector
      vizier-bootstrap: "true"
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-cloud-connector
        plane: control
        vizier-bootstrap: "true"
    spec:
      containers:
      - env:
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
              optional: true
        - name: PL_SENTRY_DSN
          value: ""
        - name: PL_DEPLOY_KEY
          valueFrom:
            secretKeyRef:
              key: deploy-key
              name: pl-deploy-secrets
              optional: true
        - name: PL_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: PL_MAX_EXPECTED_CLOCK_SKEW
          value: "2000"
        - name: PL_RENEW_PERIOD
          value: "5000"
        envFrom:
        - configMapRef:
            name: pl-cloud-config
        - configMapRef:
            name: pl-cloud-connector-tls-config
        - configMapRef:
            name: pl-cloud-connector-bootstrap-config
            optional: true
        - configMapRef:
            name: pl-cluster-config
            optional: true
        image: gcr.io/pixie-oss/pixie-prod/vizier/cloud_connector_server_image:0.7.13
        livenessProbe:
          httpGet:
            path: /healthz
            port: 50800
            scheme: HTTPS
        name: app
        ports:
        - containerPort: 50800
        volumeMounts:
        - mountPath: /certs
          name: certs
      serviceAccountName: cloud-conn-service-account
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-proxy
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-proxy
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-proxy
        plane: control
    spec:
      containers:
      - args:
        - -c
        - /etc/envoy.yaml
        - --service-cluster
        - $(POD_NAME)
        command:
        - envoy
        env:
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        - name: PL_SENTRY_DSN
          value: ""
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: envoyproxy/envoy:v1.12.2
        name: app
        ports:
        - containerPort: 55000
        volumeMounts:
        - mountPath: /etc/envoy.yaml
          name: envoy-yaml
          subPath: envoy.yaml
        - mountPath: /proxy-certs
          name: proxy-certs
        - mountPath: /certs
          name: certs
      initContainers:
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/readyz"; until [ $(curl
          -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do echo "waiting
          for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-cloud-connector
        - name: SERVICE_PORT
          value: "50800"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: cc-wait
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
      - configMap:
          name: proxy-envoy-config
        name: envoy-yaml
      - name: proxy-certs
        secret:
          secretName: proxy-tls-certs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-query-broker
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-query-broker
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-query-broker
        plane: control
    spec:
      containers:
      - env:
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        - name: PL_SENTRY_DSN
          value: ""
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        - name: PL_POD_IP_ADDRESS
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: PL_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        envFrom:
        - configMapRef:
            name: pl-tls-config
        image: gcr.io/pixie-oss/pixie-prod/vizier/query_broker_server_image:0.7.13
        livenessProbe:
          httpGet:
            path: /healthz
            port: 50300
            scheme: HTTPS
        name: app
        ports:
        - containerPort: 50300
        volumeMounts:
        - mountPath: /certs
          name: certs
      initContainers:
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/readyz"; until [ $(curl
          -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do echo "waiting
          for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-cloud-connector
        - name: SERVICE_PORT
          value: "50800"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: cc-wait
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/healthz"; until [
          $(curl -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do
          echo "waiting for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-metadata
        - name: SERVICE_PORT
          value: "50400"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: mds-wait
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
      - configMap:
          name: proxy-envoy-config
        name: envoy-yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-metadata
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-metadata
  serviceName: vizier-metadata
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-metadata
        plane: control
    spec:
      containers:
      - env:
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              key: cluster-id
              name: pl-cluster-secrets
        - name: PL_SENTRY_DSN
          value: ""
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        - name: PL_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: PL_MAX_EXPECTED_CLOCK_SKEW
          value: "2000"
        - name: PL_RENEW_PERIOD
          value: "5000"
        envFrom:
        - configMapRef:
            name: pl-tls-config
        - configMapRef:
            name: pl-cluster-config
            optional: true
        image: gcr.io/pixie-oss/pixie-prod/vizier/metadata_server_image:0.7.13
        livenessProbe:
          httpGet:
            path: /healthz
            port: 50400
            scheme: HTTPS
          initialDelaySeconds: 120
          periodSeconds: 10
        name: app
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: 50400
            scheme: HTTPS
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - mountPath: /certs
          name: certs
        - mountPath: /metadata
          name: metadata-volume
      initContainers:
      - command:
        - sh
        - -c
        - set -xe; URL="${PROTOCOL}://${SERVICE_NAME}:${SERVICE_PORT}${HEALTH_PATH}";
          until [ $(curl -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200
          ]; do echo "waiting for ${URL}"; sleep 2; done;
        env:
        - name: SERVICE_NAME
          value: pl-nats-mgmt
        - name: SERVICE_PORT
          value: "8222"
        - name: HEALTH_PATH
          value: ""
        - name: PROTOCOL
          value: http
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: nats-wait
      volumes:
      - name: certs
        secret:
          secretName: service-tls-certs
      - name: metadata-volume
        persistentVolumeClaim:
          claimName: metadata-pv-claim
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: vizier-pem
  namespace: newreliclog
spec:
  selector:
    matchLabels:
      app: pl-monitoring
      component: vizier
      name: vizier-pem
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        component: vizier
        name: vizier-pem
        plane: data
    spec:
      containers:
      - args: []
        env:
        - name: TCMALLOC_SAMPLE_PARAMETER
          value: "1048576"
        - name: PL_CLIENT_TLS_CERT
          value: /certs/client.crt
        - name: PL_CLIENT_TLS_KEY
          value: /certs/client.key
        - name: PL_TLS_CA_CERT
          value: /certs/ca.crt
        - name: PL_DISABLE_SSL
          value: "false"
        - name: PL_HOST_PATH
          value: /host
        - name: PL_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: PL_HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: PL_JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              key: jwt-signing-key
              name: pl-cluster-secrets
        image: gcr.io/pixie-oss/pixie-prod/vizier/pem_image:0.7.13
        name: pem
        resources:
          limits:
            memory: "2Gi"
        securityContext:
          capabilities:
            add:
            - SYS_PTRACE
            - SYS_ADMIN
          privileged: true
        volumeMounts:
        - mountPath: /host
          name: host-root
          readOnly: true
        - mountPath: /sys
          name: sys
          readOnly: true
        - mountPath: /certs
          name: certs
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      hostPID: true
      initContainers:
      - command:
        - sh
        - -c
        - 'set -x; URL="https://${SERVICE_NAME}:${SERVICE_PORT}/healthz"; until [
          $(curl -m 0.5 -s -o /dev/null -w "%{http_code}" -k ${URL}) -eq 200 ]; do
          echo "waiting for ${URL}" sleep 2; done; '
        env:
        - name: SERVICE_NAME
          value: vizier-query-broker
        - name: SERVICE_PORT
          value: "50300"
        image: gcr.io/pixie-prod/pixie-prod-artifacts/curl:1.0
        name: qb-wait
      terminationGracePeriodSeconds: 10
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      - effect: NoExecute
        operator: Exists
      - effect: NoSchedule
        operator: Exists
      volumes:
      - hostPath:
          path: /
          type: Directory
        name: host-root
      - hostPath:
          path: /sys
          type: Directory
        name: sys
      - name: certs
        secret:
          secretName: service-tls-certs
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 20
    type: RollingUpdate
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
    vizier-bootstrap: "true"
  name: cert-provisioner-job
  namespace: newreliclog
spec:
  backoffLimit: 1
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        app: pl-monitoring
        component: vizier
        vizier-bootstrap: "true"
      name: cert-provisioner-job
    spec:
      containers:
      - env:
        - name: PL_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        envFrom:
        - configMapRef:
            name: pl-cloud-config
        - configMapRef:
            name: pl-cluster-config
            optional: true
        image: gcr.io/pixie-oss/pixie-prod/vizier/cert_provisioner_image:0.7.13
        name: provisioner
      restartPolicy: Never
      serviceAccountName: updater-service-account
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
    component: vizier
  name: metadata-pv-claim
  namespace: newreliclog
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
# Source: nri-bundle/charts/pixie-chart/templates/01_nats.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: nats-operator
  namespace: newreliclog
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: nats-server
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: pl:nats-operator
  namespace: newreliclog
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - '*'
- apiGroups:
  - nats.io
  resources:
  - natsclusters
  - natsserviceroles
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  - pods
  - pods/exec
  - pods/log
  - services
  - serviceaccounts
  - serviceaccounts/token
  - endpoints
  - events
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: pl:nats-server
  namespace: newreliclog
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - '*'
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: pl:nats-operator-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl:nats-operator
subjects:
- kind: ServiceAccount
  name: nats-operator
  namespace: newreliclog
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: pl:nats-server-binding
  namespace: newreliclog
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pl:nats-server
subjects:
- kind: ServiceAccount
  name: nats-server
  namespace: newreliclog
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: nats-operator
  namespace: newreliclog
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pl-monitoring
      name: nats-operator
  template:
    metadata:
      annotations:
        
      labels:
        
        app: pl-monitoring
        name: nats-operator
        plane: control
    spec:
      containers:
      - args:
        - nats-operator
        env:
        - name: MY_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: connecteverything/nats-operator:0.5.0-v1alpha2
        imagePullPolicy: IfNotPresent
        name: nats-operator
        ports:
        - containerPort: 8080
          name: readyz
        readinessProbe:
          httpGet:
            path: /readyz
            port: readyz
          initialDelaySeconds: 15
          timeoutSeconds: 3
      serviceAccountName: nats-operator
---
apiVersion: nats.io/v1alpha2
kind: NatsCluster
metadata:
  annotations:
    
  labels:
    
    app: pl-monitoring
  name: pl-nats
  namespace: newreliclog
spec:
  size: 1
  tls:
    serverSecret: service-tls-certs
    serverSecretCAFileName: ca.crt
    serverSecretCertFileName: server.crt
    serverSecretKeyFileName: server.key
  version: 1.3.0

---
# Source: nri-bundle/charts/pixie-chart/templates/00_secrets.yaml
---
apiVersion: v1
data:
  PL_CLOUD_ADDR: "withpixie.ai:443"
  PL_CLUSTER_NAME: "api-kpmgocp-stotenrhos-com:6443"
  PL_UPDATE_CLOUD_ADDR: "withpixie.ai:443"
kind: ConfigMap
metadata:
  annotations:
    
  creationTimestamp: null
  labels:
    
  name: pl-cloud-config
  namespace: newreliclog
---
apiVersion: v1
data:
  PL_CUSTOM_ANNOTATIONS: ""
  PL_CUSTOM_LABELS: ""
  PL_DISABLE_AUTO_UPDATE: "false"
  PL_ETCD_OPERATOR_ENABLED: "false"
  PL_MD_ETCD_SERVER: "https://etcd.newreliclog.svc:2379"
  PX_MEMORY_LIMIT: ""
kind: ConfigMap
metadata:
  annotations:
    
  creationTimestamp: null
  labels:
    
  name: pl-cluster-config
  namespace: newreliclog
---
apiVersion: v1
kind: Secret
metadata:
  annotations:
    
  creationTimestamp: null
  labels:
    
  name: pl-cluster-secrets
  namespace: newreliclog
stringData:
  sentry-dsn: https://a8a635734bb840799befb63190e904e0@o324879.ingest.sentry.io/5203506
---
apiVersion: v1
data:
  PL_BOOTSTRAP_MODE: "false"
  PL_BOOTSTRAP_VERSION: ""
kind: ConfigMap
metadata:
  annotations:
    
  creationTimestamp: null
  labels:
    
    component: vizier
  name: pl-cloud-connector-bootstrap-config
  namespace: newreliclog
---
apiVersion: v1
kind: Secret
metadata:
  annotations:
    
  creationTimestamp: null
  labels:
    
  name: pl-deploy-secrets
  namespace: newreliclog
stringData:
  deploy-key: "80df68ab-642c-470d-a16a-ae474557af69"

---
# Source: nri-bundle/charts/nri-kube-events/templates/serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"
  name: nri-bundle-nri-kube-events
  namespace: newreliclog
  annotations:
    null
    
---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:     
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-2.4.8
    release: nri-bundle
    mode: privileged
  name: nri-bundle-newrelic-infrastructure
rules:
  - apiGroups: [""]
    resources:
      - "nodes"
      - "nodes/metrics"
      - "nodes/stats"
      - "nodes/proxy"
      - "pods"
      - "services"
    verbs: ["get", "list"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
---
# Source: nri-bundle/charts/kube-state-metrics/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: kube-state-metrics-2.13.2
    app.kubernetes.io/instance: nri-bundle
  name: nri-bundle-kube-state-metrics
  namespace: newreliclog
imagePullSecrets:
  []
  
---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - mutatingwebhookconfigurations
    verbs:
      - get
      - update
  - apiGroups: ['extensions']
    resources: ['podsecuritypolicies']
    verbs: ['use']
    resourceNames:
    - nri-bundle-nri-metadata-injection-admission

---
# Source: nri-bundle/charts/nri-kube-events/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"
  name: nri-bundle-nri-kube-events
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-kube-events
subjects:
- kind: ServiceAccount
  name: nri-bundle-nri-kube-events
  namespace: newreliclog
---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/rolebinding.yaml

---
# Source: nri-bundle/charts/kube-state-metrics/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: kube-state-metrics-2.13.2
    app.kubernetes.io/instance: nri-bundle
  name: nri-bundle-kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: nri-bundle-kube-state-metrics
  namespace: newreliclog
---
# Source: nri-bundle/charts/pixie-chart/templates/03_vizier_etcd.yaml

---
# Source: nri-bundle/charts/newrelic-logging/templates/serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: newreliclog
  labels:
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: "nri-bundle"
  annotations:
  name: nri-bundle-newrelic-logging
---
# Source: nri-bundle/charts/newrelic-logging/templates/daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: nri-bundle
    app.kubernetes.io/name: newrelic-logging
  name: nri-bundle-newrelic-logging
  annotations:
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: newrelic-logging
      release: nri-bundle
  template:
    metadata:
      labels:
        app: newrelic-logging
        release: nri-bundle
        app.kubernetes.io/name: newrelic-logging
    spec:
      serviceAccountName: nri-bundle-newrelic-logging
      hostNetwork: true # This option is a requirement for the Infrastructure Agent to report the proper hostname in New Relic.
      dnsPolicy: ClusterFirstWithHostNet
      terminationGracePeriodSeconds: 10
      containers:
        - name: newrelic-logging
          image: "newrelic/newrelic-fluentbit-output:1.4.6"
          imagePullPolicy: "IfNotPresent"
          env:
            - name: ENDPOINT
              value: "https://log-api.newrelic.com/log/v1"
            - name: SOURCE
              value: "kubernetes"
            - name: LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: nri-bundle-newrelic-logging-config
                  key: license
            - name: CLUSTER_NAME
              value: api-kpmgocp-stotenrhos-com:6443
            - name: LOG_LEVEL
              value: "info"
            - name: LOG_PARSER
              value: "docker"
            - name: PATH
              value: "/var/log/containers/*.log"
            - name: K8S_LOGGING_EXCLUDE
              value: "Off"
          command:
            - /fluent-bit/bin/fluent-bit
            - -c
            - /fluent-bit/etc/fluent-bit.conf
            - -e
            - /fluent-bit/bin/out_newrelic.so
          volumeMounts:
            - name: fluent-bit-config
              mountPath: /fluent-bit/etc
            - name: var
              mountPath: /var
          resources:
            limits:
              cpu: 500m
              memory: 128Mi
            requests:
              cpu: 250m
              memory: 64Mi
            
      volumes:
        - name: fluent-bit-config
          configMap:
            name: nri-bundle-newrelic-logging-fluent-bit-config
        - name: var
          hostPath:
            path: /var
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        

---
# Source: nri-bundle/charts/newrelic-logging/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:     
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: nri-bundle
    app.kubernetes.io/name: newrelic-logging
  name: nri-bundle-newrelic-logging
rules:
  - apiGroups: [""]
    resources:
      - namespaces
      - pods
    verbs: ["get", "list", "watch"]
---
# Source: nri-bundle/charts/kube-state-metrics/templates/rolebinding.yaml

---
# Source: nri-bundle/charts/kube-state-metrics/templates/psp-clusterrole.yaml


---
# Source: nri-bundle/charts/nri-prometheus/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-prometheus
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-prometheus
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nri-prometheus
        helm.sh/chart: nri-prometheus-1.8.2
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/version: "2.7.0"
    spec:
      serviceAccountName: nri-prometheus
      containers:
      - name: nri-prometheus
        image: newrelic/nri-prometheus:2.7.0
        args:
          - "--configfile=/etc/nri-prometheus/config.yaml"
        ports:
          - containerPort: 8080
        volumeMounts:
        - name: config-volume
          mountPath: /etc/nri-prometheus/
        env:
          - name: "LICENSE_KEY"
            valueFrom:
                secretKeyRef:
                  name: nri-bundle-nri-prometheus-config
                  key: licenseKey
          - name: "BEARER_TOKEN_FILE"
            value: "/var/run/secrets/kubernetes.io/serviceaccount/token"
          - name: "CA_FILE"
            value: "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
      volumes:
        - name: config-volume
          configMap:
            name: nri-bundle-nri-prometheus-config

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nri-bundle-nri-metadata-injection
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
spec:
  ports:
  - port: 443
    targetPort: 8443
  selector:
    app.kubernetes.io/name: nri-metadata-injection

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-metadata-injection
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-metadata-injection
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nri-metadata-injection
        helm.sh/chart: nri-metadata-injection-1.5.1
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/version: "1.5.0"
    spec:
      # Switching from dedicated service account to default one must be
      # done explicitly, otherwise upgrade fails, trying to use old
      # service account.
      serviceAccount: default
      containers:
      - name: nri-metadata-injection
        image: "newrelic/k8s-metadata-injection:1.5.0"
        imagePullPolicy: "IfNotPresent"
        env:
        - name: clusterName
          value: api-kpmgocp-stotenrhos-com:6443
        volumeMounts:
        - name: tls-key-cert-pair
          mountPath: /etc/tls-key-cert-pair
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 1
          periodSeconds: 1
        resources:
          limits:
            memory: 80M
          requests:
            cpu: 100m
            memory: 30M
          
      volumes:
      - name: tls-key-cert-pair
        secret:
          secretName: nri-bundle-nri-metadata-injection-admission

---
# Source: nri-bundle/charts/newrelic-logging/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: nri-bundle
    app.kubernetes.io/name: newrelic-logging
  name: nri-bundle-newrelic-logging-fluent-bit-config
data:
  # Configuration files: server, input, filters and output
  # ======================================================
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     ${LOG_LEVEL}
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE input-kubernetes.conf
    @INCLUDE output-newrelic.conf
    @INCLUDE filter-kubernetes.conf

  input-kubernetes.conf: |
    [INPUT]
        Name              tail
        Tag               kube.*
        Path              ${PATH}
        Parser            ${LOG_PARSER}
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     7MB
        Skip_Long_Lines   On
        Refresh_Interval  10

  filter-kubernetes.conf: |
    [FILTER]
        Name           record_modifier
        Match          *
        Record         cluster_name ${CLUSTER_NAME}

    [FILTER]
        Name           kubernetes
        Match          kube.*
        Kube_URL       https://kubernetes.default.svc:443
        K8S-Logging.Exclude ${K8S_LOGGING_EXCLUDE}

  output-newrelic.conf: |
    [OUTPUT]
        Name  newrelic
        Match *
        licenseKey ${LICENSE_KEY}
        endpoint ${ENDPOINT}

  parsers.conf: |
    # Relevant parsers retrieved from: https://github.com/fluent/fluent-bit/blob/master/conf/parsers.conf
    [PARSER]
        Name         docker
        Format       json
        Time_Key     time
        Time_Format  %Y-%m-%dT%H:%M:%S.%L
        Time_Keep    On

    [PARSER]
        Name cri
        Format regex
        Regex ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z

---
# Source: nri-bundle/charts/kube-state-metrics/templates/psp-clusterrolebinding.yaml


---
# Source: nri-bundle/charts/nri-kube-events/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
data:
  config.yaml: |-
    sinks:
    - name: newRelicInfra
      config:
        agentEndpoint: http://localhost:8001/v1/data
        clusterName: api-kpmgocp-stotenrhos-com:6443
        agentHTTPTimeout: 30s
metadata:
  name: nri-bundle-nri-kube-events-config
  namespace: newreliclog
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"


---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/secret.yaml

apiVersion: v1
kind: Secret
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-2.4.8
    release: nri-bundle
    mode: privileged
  name: nri-bundle-newrelic-infrastructure-config
type: Opaque
data:
  license: OWYxZjgzN2VlOTJlNjNjNjFhOGMwMzRiY2MzMDBlZTVjNjY0TlJBTA==

---
# Source: nri-bundle/charts/kube-state-metrics/templates/stsdiscovery-role.yaml


---
# Source: nri-bundle/charts/kube-state-metrics/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nri-bundle-kube-state-metrics
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: "kube-state-metrics-2.13.2"
    app.kubernetes.io/instance: "nri-bundle"
  annotations:
    prometheus.io/scrape: 'true'
spec:
  type: "ClusterIP"
  ports:
  - name: "http"
    protocol: TCP
    port: 8080
    targetPort: 8080
  
  selector:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: nri-bundle

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:     
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-2.4.8
    release: nri-bundle
    mode: privileged
  name: nri-bundle-newrelic-infrastructure
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-newrelic-infrastructure
subjects:
- kind: ServiceAccount
  name: nri-bundle-newrelic-infrastructure
  namespace: newreliclog
---
# Source: nri-bundle/charts/nri-prometheus/templates/secret.yaml

apiVersion: v1
kind: Secret
metadata:
  name: nri-bundle-nri-prometheus-config
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
type: Opaque
data:
  licenseKey: OWYxZjgzN2VlOTJlNjNjNjFhOGMwMzRiY2MzMDBlZTVjNjY0TlJBTA==

---
# Source: nri-bundle/charts/nri-prometheus/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nri-bundle-nri-prometheus
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
rules:
- apiGroups: [""]
  resources:
    - "nodes"
    - "nodes/metrics"
    - "nodes/stats"
    - "nodes/proxy"
    - "pods"
    - "services"
    - "endpoints"
  verbs: ["get", "list", "watch"]
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
# Source: nri-bundle/charts/nri-metadata-injection/templates/cert-manager.yaml


---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/role.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  namespace: newreliclog
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/job-createSecret.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: nri-bundle-nri-metadata-injection-admission-create
  namespace: newreliclog
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission-create
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
spec:
  template:
    metadata:
      name: nri-bundle-nri-metadata-injection-admission-create
      labels:
        app: nri-metadata-injection-admission-create
        app.kubernetes.io/name: nri-metadata-injection
        helm.sh/chart: nri-metadata-injection-1.5.1
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/version: "1.5.0"
    spec:
      containers:
        - name: create
          image: jettech/kube-webhook-certgen:v1.5.0
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=nri-bundle-nri-metadata-injection,nri-bundle-nri-metadata-injection.newreliclog.svc
            - --namespace=newreliclog
            - --secret-name=nri-bundle-nri-metadata-injection-admission
            - --cert-name=tls.crt
            - --key-name=tls.key
      restartPolicy: OnFailure
      serviceAccountName: nri-bundle-nri-metadata-injection-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/mutatingWebhookConfiguration.yaml
apiVersion: admissionregistration.k8s.io/v1beta1
kind: MutatingWebhookConfiguration
metadata:
  name: nri-bundle-nri-metadata-injection
  labels:
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
webhooks:
- name: metadata-injection.newrelic.com
  clientConfig:
    service:
      name: nri-bundle-nri-metadata-injection
      namespace: newreliclog
      path: "/mutate"
    caBundle: ""
  rules:
  - operations: ["CREATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  failurePolicy: Ignore


---
# Source: nri-bundle/charts/kube-state-metrics/templates/servicemonitor.yaml


---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/psp.yaml

apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: nri-metadata-injection-admission
    app.kubernetes.io/name: nri-metadata-injection
    helm.sh/chart: nri-metadata-injection-1.5.1
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.0"
spec:
  privileged: false
  # Required to prevent escalations to root.
  # allowPrivilegeEscalation: false
  # This is redundant with non-root + disallow privilege escalation,
  # but we can provide it for defense in depth.
  #requiredDropCapabilities:
  #  - ALL
  # Allow core volume types.
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    # Permits the container to run with root privileges as well.
    rule: 'RunAsAny'
  seLinux:
    # This policy assumes the nodes are using AppArmor rather than SELinux.
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'MustRunAs'
    ranges:
      # Forbid adding the root group.
      - min: 0
        max: 65535
  fsGroup:
    rule: 'MustRunAs'
    ranges:
      # Forbid adding the root group.
      - min: 0
        max: 65535
  readOnlyRootFilesystem: false

---
# Source: nri-bundle/charts/nri-prometheus/templates/configmap.yaml
kind: ConfigMap
metadata:
  name: nri-bundle-nri-prometheus-config
  namespace: newreliclog
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.8.2
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "2.7.0"
apiVersion: v1
data:
  config.yaml: |
    cluster_name: api-kpmgocp-stotenrhos-com:6443
    audit: false
    insecure_skip_verify: false
    require_scrape_enabled_label_for_nodes: true
    scrape_enabled_label: prometheus.io/scrape
    scrape_endpoints: false
    scrape_services: true
    verbose: false
    

---
# Source: nri-bundle/charts/newrelic-logging/templates/secret.yaml

apiVersion: v1
kind: Secret
metadata:
  namespace: newreliclog
  labels:     
    app: newrelic-logging
    chart: newrelic-logging-1.4.8
    release: nri-bundle
    app.kubernetes.io/name: newrelic-logging
  name: nri-bundle-newrelic-logging-config
type: Opaque
data:
  license: OWYxZjgzN2VlOTJlNjNjNjFhOGMwMzRiY2MzMDBlZTVjNjY0TlJBTA==

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/configmap.yaml



---
# Source: nri-bundle/charts/nri-kube-events/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-kube-events
  namespace: newreliclog
  labels:
    app: nri-kube-events
    app.kubernetes.io/name: nri-kube-events
    helm.sh/chart: nri-kube-events-1.9.3
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/version: "1.5.1"
  annotations:
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-kube-events
  template:
    metadata:
      labels:
        app: nri-kube-events
        app.kubernetes.io/name: nri-kube-events
        helm.sh/chart: nri-kube-events-1.9.3
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/version: "1.5.1"
    spec:
      securityContext:
        runAsUser: 1000
        runAsNonRoot: true
      containers:
        - name: kube-events
          image: newrelic/nri-kube-events:1.5.1
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          args: ["-config", "/app/config/config.yaml", "-loglevel", "debug"]
          volumeMounts:
            - name: config-volume
              mountPath: /app/config
        - name: infra-agent
          image: newrelic/k8s-events-forwarder:1.18.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 8001
          env:
            - name: NRIA_LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: nri-bundle-nri-kube-events-config
                  key: licenseKey
          volumeMounts:
            - mountPath: /var/db/newrelic-infra/data
              name: tmpfs-data
            - mountPath: /var/db/newrelic-infra/user_data
              name: tmpfs-user-data
            - mountPath: /tmp
              name: tmpfs-tmp
      serviceAccountName: nri-bundle-nri-kube-events
      volumes:
        - name: config-volume
          configMap:
            name: nri-bundle-nri-kube-events-config
        - name: tmpfs-data
          emptyDir: {}
        - name: tmpfs-user-data
          emptyDir: {}
        - name: tmpfs-tmp
          emptyDir: {}

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: newreliclog
  labels:
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-2.4.8
    release: "nri-bundle"
  annotations:
    null
    
  name: nri-bundle-newrelic-infrastructure
